# Light Field Images Compression

This repository contains the project developed for the *Data Compression* exam.
The goal is to evaluate the performance of different codecs for **compressing Light Field Images (LFI)** through benchmarks on different datasets and a written report.

The project compares three main approaches:
1.  **JPEG Pleno (Part 2 - 4D Transform Mode):** The standard specifically designed for plenoptic imaging.
2.  **Standard Video Codecs (HEVC, AV1, VP9):** Applied by treating the Light Field views as a pseudo-temporal video sequence.
3.  **EPI Approach (Epipolar Plane Images):** A hybrid technique that transforms the 4D volume into EPIs to exploit geometric linearity before applying video codecs.

## üìÑ Report
The complete analysis, methodology, and results are detailed in the final report included in this repository: [light_field_image_compression.pdf](./light_field_image_compression.pdf).

## üñ•Ô∏è Experimental Setup
To ensure consistency in compression and decompression times, all tests were performed on the following hardware:
- **CPU:** AMD Ryzen 7 6800H (8 cores, SMT, 3.2 GHz base, up to 4.7 GHz boost)  
- **GPU:** NVIDIA GeForce RTX 3060 Mobile (3840 CUDA cores, 900 MHz base, up to 1425 MHz boost)  
- **OS:** Windows 11 with WSL

## üìÇ Repository Structure
```text
‚îú‚îÄ‚îÄ codec_video.py                     # Video codec compressor and decompressor (HEVC, AV1, VP9)
‚îú‚îÄ‚îÄ compare_debug.py                   # Visual comparison of images for debugging purposes
‚îú‚îÄ‚îÄ compare.py                         # Evaluate compression performance of every codec for a specific dataset
‚îú‚îÄ‚îÄ epi_codec_video.py                 # Video codec compressor and decompressor which uses EPI images (HEVC, AV1, VP9)
‚îú‚îÄ‚îÄ jpl_processor.py                   # JPEG Pleno compressor and decompressor
‚îú‚îÄ‚îÄ raw_check.py                       # Header Check for PPM files
‚îú‚îÄ‚îÄ light_field_image_compression.pdf  # Final report
‚îî‚îÄ‚îÄ results.xlsx                       # Excel document with benchmarks results
```

## ‚öôÔ∏è Dataset Organization
**Crucial**: You must create a `datasets` folder in the root of the project. Inside `datasets`, create a subfolder for each dataset (e.g., `Bikes`, `Danger_de_Mort`, `Greek`, etc.). The raw images must be placed inside `RAW/PPM`.

The directory structure must look like this:

```text
project_root/
‚îÇ
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ [Dataset_Name]/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RAW/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ PPM/       <-- Put your original .ppm files here
```

**Note**: Ensure all input images are in .ppm format.

You can find all the datasets used in this project and others at the following link [JPEG Pleno Light Field Datasets](https://plenodb.jpeg.org/lf/pleno_lf).

## ‚ñ∂Ô∏è How to Run

### Requirements
- Python 3
- [FFMPEG](https://www.ffmpeg.org/) (accessible via command line)
- [JPEG Pleno Reference Software (JPLM)](https://gitlab.com/wg1/jpeg-pleno-refsw) (compiled binaries required)
- Python libraries: `numpy`, `opencv-python-headless`, `scikit-image`, `Pillow`

### Execution

> [!WARNING] 
> For **Lenslet** datasets (acquired via microlens arrays), the raw data has a hexagonal arrangement that requires rectification. **You MUST run STEP 1 (Shifting) of `jpl_processor.py` BEFORE running any other script.** The other scripts (`codec_video`, `epi_codec_video`, `compare`) rely on the shifted data generated by this step.

#### 1. JPL Processor (`jpl_processor.py`)
Handles the JPEG Pleno pipeline. This script manages shifting (for lenslet datasets), encoding, and decoding.

**Usage**:

```
jpl_processor.py [-h] --lenslet | --no-lenslet [--steps STEPS] [--lambda LAMBDA_VALUE] dataset_name
```

*Example*:

```
python jpl_processor.py Bikes --lenslet
```

Run `python jpl_processor.py --help` for full options.

#### 2. Video Codec (`codec_video.py`)
Compresses the Light Field by treating the views as a video sequence (Pseudo-Sequence). Supports HEVC, AV1, and VP9.

**Usage**:

```
 codec_video.py [-h] --lenslet | --no-lenslet [--crf_hevc CRF_HEVC] [--crf_av1 CRF_AV1] [--crf_vp9 CRF_VP9] dataset_name
```

*Example*:

```
python codec_video.py Bikes --lenslet
```

Run `python codec_video.py --help` for full options.

#### 3. EPI Video Codec (`epi_codec_video.py`)
Transforms the Light Field volume into Epipolar Plane Images (EPIs) and then applies video compression. Supports HEVC, AV1, and VP9.

**Usage**:

```
 epi_codec_video.py [-h] --lenslet | --no-lenslet [--crf_hevc CRF_HEVC] [--crf_av1 CRF_AV1] [--crf_vp9 CRF_VP9] dataset_name
```

*Example*:

```
python epi_codec_video.py Bikes --lenslet
```

Run `python epi_codec_video.py --help` for full options.

#### 4. Compare (`compare.py`)
Collects results and calculates quality metrics (SSIM, PSNR).

**Usage**:

```
 compare.py [-h] --lenslet | --no-lenslet [-c CODECS] dataset_name
```

*Example*:

```
python compare.py Bikes --lenslet
```

Run `python compare.py --help` for full options.

*This script expects that you have already run the compression/decompression scripts for the selected dataset.*

## üìä Results Summary
Experiments on heterogeneous datasets (Lenslet, Synthetic and HDCA) showed that there is no single winner:

- **Dense Datasets (Lenslet - e.g., Bikes):**

    - üèÜ **JPEG Pleno (4D-TM)** is superior, producing extremely small files with high quality.

    - The **EPI approach** works well, outperforming standard video coding due to the continuous linear structures.

- **Sparse Datasets (Synthetic and HDCA - e.g., Greek, Tarot):**

    - üèÜ **Video Codecs (especially AV1)** dominate. On *Tarot*, AV1 achieved ~1000:1 compression ratio.

    - **JPEG Pleno** struggles due to the wide baseline (lack of correlation).

    - The **EPI approach** performs poorly here due to angular aliasing and steep discontinuities.